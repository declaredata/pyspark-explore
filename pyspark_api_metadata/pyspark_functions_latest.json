{
  "timestamp": "2024-11-22T23:16:53.358527",
  "pyspark_version": "3.5.3",
  "function_count": 2103,
  "functions": [
    "NamedTemporaryFile",
    "NamedTuple",
    "None.fromhex",
    "None.fromkeys",
    "RLock",
    "_functools.reduce",
    "_pickle.load",
    "_pickle.loads",
    "_warnings.warn",
    "abc.abstractmethod",
    "abs",
    "abstractmethod",
    "accumulator",
    "acos",
    "acosh",
    "active",
    "add",
    "addArchive",
    "addArtifact",
    "addArtifacts",
    "addFile",
    "addInPlace",
    "addJobTag",
    "addListener",
    "addPyFile",
    "addTag",
    "add_function",
    "add_months",
    "add_profiler",
    "aes_decrypt",
    "aes_encrypt",
    "agg",
    "aggregate",
    "aggregateByKey",
    "alias",
    "allGather",
    "any_value",
    "appName",
    "append",
    "apply",
    "applyInPandas",
    "applyInPandasWithState",
    "approxCountDistinct",
    "approxQuantile",
    "approx_count_distinct",
    "approx_percentile",
    "array",
    "array_agg",
    "array_append",
    "array_compact",
    "array_contains",
    "array_distinct",
    "array_except",
    "array_insert",
    "array_intersect",
    "array_join",
    "array_max",
    "array_min",
    "array_position",
    "array_prepend",
    "array_remove",
    "array_repeat",
    "array_size",
    "array_sort",
    "array_union",
    "arrays_overlap",
    "arrays_zip",
    "arrow_to_pandas",
    "asDeterministic",
    "asDict",
    "asNondeterministic",
    "asc",
    "asc_nulls_first",
    "asc_nulls_last",
    "ascii",
    "asin",
    "asinh",
    "assert_true",
    "astype",
    "atan",
    "atan2",
    "atanh",
    "attemptNumber",
    "avg",
    "awaitAnyTermination",
    "awaitTermination",
    "barrier",
    "base64",
    "between",
    "bin",
    "binaryFiles",
    "binaryRecords",
    "bit_and",
    "bit_count",
    "bit_get",
    "bit_length",
    "bit_or",
    "bit_xor",
    "bitmap_bit_position",
    "bitmap_bucket_number",
    "bitmap_construct_agg",
    "bitmap_count",
    "bitmap_or_agg",
    "bitwiseAND",
    "bitwiseNOT",
    "bitwiseOR",
    "bitwiseXOR",
    "bitwise_not",
    "bool_and",
    "bool_or",
    "broadcast",
    "bround",
    "btrim",
    "bucket",
    "bucketBy",
    "cache",
    "cacheTable",
    "call",
    "call_function",
    "call_udf",
    "can_convert",
    "cancelAllJobs",
    "cancelJobGroup",
    "cancelJobsWithTag",
    "capture_sql_exception",
    "cardinality",
    "cartesian",
    "cast",
    "cbrt",
    "ceil",
    "ceiling",
    "cell_set",
    "char",
    "char_length",
    "character_length",
    "check_iterator_annotation",
    "check_tuple_annotation",
    "check_union_annotation",
    "check_unused_args",
    "checkpoint",
    "choose_backend",
    "cleanShuffleDependencies",
    "clear",
    "clearCache",
    "clearExecutorResourceRequests",
    "clearJobTags",
    "clearTags",
    "clearTaskResourceRequests",
    "close",
    "close_request",
    "coalesce",
    "cogroup",
    "col",
    "colRegex",
    "collect",
    "collectAsMap",
    "collectWithJobGroup",
    "collect_list",
    "collect_set",
    "collections.namedtuple",
    "column",
    "combineByKey",
    "concat",
    "concat_ws",
    "config",
    "contains",
    "contextlib.contextmanager",
    "contextmanager",
    "conv",
    "convert",
    "convert_exception",
    "convert_field",
    "convert_timezone",
    "copy",
    "copyFromLocalToFs",
    "copy_func",
    "cores",
    "corr",
    "cos",
    "cosh",
    "cot",
    "count",
    "countApprox",
    "countApproxDistinct",
    "countByKey",
    "countByValue",
    "countDistinct",
    "count_distinct",
    "count_if",
    "count_min_sketch",
    "cov",
    "covar_pop",
    "covar_samp",
    "cpus",
    "crc32",
    "create",
    "createDataFrame",
    "createExternalTable",
    "createGlobalTempView",
    "createOrReplace",
    "createOrReplaceGlobalTempView",
    "createOrReplaceTempView",
    "createTable",
    "createTempView",
    "create_map",
    "crossJoin",
    "crosstab",
    "csc",
    "csv",
    "cube",
    "cume_dist",
    "curdate",
    "currentCatalog",
    "currentDatabase",
    "current_catalog",
    "current_database",
    "current_date",
    "current_schema",
    "current_timestamp",
    "current_timezone",
    "current_user",
    "databaseExists",
    "date_add",
    "date_diff",
    "date_format",
    "date_from_unix_date",
    "date_part",
    "date_sub",
    "date_trunc",
    "dateadd",
    "datediff",
    "datepart",
    "day",
    "dayofmonth",
    "dayofweek",
    "dayofyear",
    "days",
    "decode",
    "degrees",
    "dense_rank",
    "desc",
    "desc_nulls_first",
    "desc_nulls_last",
    "describe",
    "deserialize",
    "destroy",
    "df_varargs_api",
    "dfapi",
    "disable",
    "disable_by_count",
    "distinct",
    "drop",
    "dropDuplicates",
    "dropDuplicatesWithinWatermark",
    "dropFields",
    "dropGlobalTempView",
    "dropTempTable",
    "dropTempView",
    "drop_duplicates",
    "dropna",
    "dump",
    "dump_profiles",
    "dump_stream",
    "dumps",
    "dynamic_subimport",
    "e",
    "element_at",
    "elt",
    "emptyRDD",
    "enable",
    "enableHiveSupport",
    "enable_by_count",
    "encode",
    "endswith",
    "ensure_callback_server_started",
    "eqNullSafe",
    "equal_null",
    "every",
    "exceptAll",
    "exception",
    "exists",
    "exp",
    "explain",
    "explode",
    "explode_outer",
    "expm1",
    "expr",
    "extract",
    "factorial",
    "fail_on_stopiteration",
    "fieldNames",
    "fileno",
    "fill",
    "fillna",
    "filter",
    "filterwarnings",
    "find_in_set",
    "finish_request",
    "first",
    "first_spark_call",
    "first_value",
    "flatMap",
    "flatMapValues",
    "flatten",
    "flattened_serializer",
    "floor",
    "fold",
    "foldByKey",
    "forall",
    "foreach",
    "foreachBatch",
    "foreachPartition",
    "format",
    "format_field",
    "format_number",
    "format_string",
    "freqItems",
    "fromInternal",
    "fromJObject",
    "fromJson",
    "from_arrow_schema",
    "from_arrow_type",
    "from_csv",
    "from_json",
    "from_unixtime",
    "from_utc_timestamp",
    "fromhex",
    "fromkeys",
    "fullOuterJoin",
    "func",
    "functionExists",
    "functools.wraps",
    "get",
    "getActiveJobsIds",
    "getActiveSession",
    "getActiveStageIds",
    "getAll",
    "getCheckpointDir",
    "getCheckpointFile",
    "getConf",
    "getCurrentProcessingTimeMs",
    "getCurrentWatermarkMs",
    "getDatabase",
    "getErrorClass",
    "getField",
    "getFunction",
    "getItem",
    "getJobIdsForGroup",
    "getJobInfo",
    "getJobTags",
    "getLocalProperty",
    "getMessageParameters",
    "getName",
    "getNumPartitions",
    "getOrCreate",
    "getPoissonSample",
    "getResourceProfile",
    "getRootDirectory",
    "getSqlState",
    "getStageInfo",
    "getStorageLevel",
    "getTable",
    "getTags",
    "getTaskInfos",
    "getUniformSample",
    "get_active_spark_context",
    "get_column_class",
    "get_dataframe_class",
    "get_error_message",
    "get_field",
    "get_json_object",
    "get_message_template",
    "get_request",
    "get_type_hints",
    "get_used_memory",
    "get_value",
    "get_window_class",
    "getbit",
    "getfullargspec",
    "glom",
    "greatest",
    "groupBy",
    "groupByKey",
    "groupWith",
    "groupby",
    "grouping",
    "grouping_id",
    "hadoopFile",
    "hadoopRDD",
    "handle_error",
    "handle_request",
    "handle_timeout",
    "hash",
    "head",
    "hex",
    "hint",
    "histogram",
    "histogram_numeric",
    "hll_sketch_agg",
    "hll_sketch_estimate",
    "hll_union",
    "hll_union_agg",
    "hour",
    "hours",
    "hypot",
    "id",
    "ifnull",
    "ilike",
    "infer_eval_type",
    "inheritable_thread_target",
    "initRandomGenerator",
    "initcap",
    "inline",
    "inline_outer",
    "inputFiles",
    "input_file_block_length",
    "input_file_block_start",
    "input_file_name",
    "insertInto",
    "inspect.getfullargspec",
    "inspect.signature",
    "install_exception_handler",
    "instance",
    "instr",
    "interruptAll",
    "interruptOperation",
    "interruptTag",
    "intersect",
    "intersectAll",
    "intersection",
    "isCached",
    "isCheckpointed",
    "isDaemon",
    "isEmpty",
    "isLocal",
    "isLocallyCheckpointed",
    "isModifiable",
    "isNotNull",
    "isNull",
    "is_alive",
    "is_instance_of",
    "is_remote",
    "is_timestamp_ntz_preferred",
    "is_tornado_coroutine",
    "isin",
    "isinf",
    "isnan",
    "isnotnull",
    "isnull",
    "items",
    "java_import",
    "java_method",
    "jdbc",
    "join",
    "json",
    "jsonValue",
    "json_array_length",
    "json_object_keys",
    "json_tuple",
    "keyBy",
    "keys",
    "keyword_only",
    "kurtosis",
    "lag",
    "last",
    "last_day",
    "last_value",
    "launch_gateway",
    "lcase",
    "lead",
    "least",
    "left",
    "leftOuterJoin",
    "length",
    "levenshtein",
    "like",
    "limit",
    "listCatalogs",
    "listColumns",
    "listDatabases",
    "listFunctions",
    "listTables",
    "list_registry_pickle_by_value",
    "lit",
    "ln",
    "load",
    "load_from_path",
    "load_stream",
    "loads",
    "localCheckpoint",
    "local_connect_and_auth",
    "localtimestamp",
    "locate",
    "log",
    "log10",
    "log1p",
    "log2",
    "lookup",
    "lower",
    "lpad",
    "ltrim",
    "majorMinorVersion",
    "make_date",
    "make_dt_interval",
    "make_interval",
    "make_timestamp",
    "make_timestamp_ltz",
    "make_timestamp_ntz",
    "make_ym_interval",
    "map",
    "mapInArrow",
    "mapInPandas",
    "mapPartitions",
    "mapPartitionsWithIndex",
    "mapPartitionsWithSplit",
    "mapValues",
    "map_concat",
    "map_contains_key",
    "map_entries",
    "map_filter",
    "map_from_arrays",
    "map_from_entries",
    "map_keys",
    "map_values",
    "map_zip_with",
    "mask",
    "master",
    "math.ceil",
    "math.isinf",
    "math.isnan",
    "math.log",
    "math.pow",
    "math.sqrt",
    "max",
    "max_by",
    "md5",
    "mean",
    "meanApprox",
    "median",
    "melt",
    "memory",
    "memoryOverhead",
    "memory_profiler.choose_backend",
    "memory_profiler.disable",
    "memory_profiler.disable_by_count",
    "memory_profiler.enable",
    "memory_profiler.enable_by_count",
    "memory_profiler.items",
    "memory_profiler.runctx",
    "memory_profiler.trace",
    "memory_profiler.trace_max_mem",
    "memory_profiler.trace_memory_usage",
    "memory_profiler.wrap_function",
    "merge",
    "mergeCombiners",
    "mergeStats",
    "mergeValues",
    "min",
    "min_by",
    "minute",
    "mode",
    "module",
    "monotonically_increasing_id",
    "month",
    "months",
    "months_between",
    "name",
    "named_struct",
    "namedtuple",
    "nanvl",
    "needConversion",
    "negate",
    "negative",
    "newAPIHadoopFile",
    "newAPIHadoopRDD",
    "newSession",
    "new_memory_profiler",
    "new_profiler",
    "new_udf_profiler",
    "next_day",
    "no_type_check",
    "now",
    "nth_value",
    "ntile",
    "nullif",
    "nvl",
    "nvl2",
    "observe",
    "octet_length",
    "offheapMemory",
    "offset",
    "onQueryIdle",
    "onQueryProgress",
    "onQueryStarted",
    "onQueryTerminated",
    "option",
    "options",
    "orc",
    "orderBy",
    "otherwise",
    "outputMode",
    "over",
    "overlay",
    "overload",
    "overwrite",
    "overwritePartitions",
    "pack_long",
    "pandas_api",
    "pandas_udf",
    "parallelize",
    "parametrized_type_hint_getinitargs",
    "parquet",
    "parse",
    "parse_url",
    "partitionBy",
    "partitionId",
    "partitionedBy",
    "percent_rank",
    "percentile",
    "percentile_approx",
    "persist",
    "pi",
    "pickleFile",
    "pipe",
    "pivot",
    "pmod",
    "portable_hash",
    "posexplode",
    "posexplode_outer",
    "position",
    "positive",
    "pow",
    "power",
    "printSchema",
    "print_exec",
    "printf",
    "processAllAvailable",
    "process_request",
    "product",
    "profile",
    "py4j.java_gateway.is_instance_of",
    "py4j.java_gateway.java_import",
    "py4j.protocol.register_input_converter",
    "pyarrow_version_less_than_minimum",
    "pyspark.accumulators.add",
    "pyspark.accumulators.addInPlace",
    "pyspark.accumulators.shutdown",
    "pyspark.accumulators.zero",
    "pyspark.broadcast.add",
    "pyspark.broadcast.clear",
    "pyspark.broadcast.destroy",
    "pyspark.broadcast.dump",
    "pyspark.broadcast.load",
    "pyspark.broadcast.load_from_path",
    "pyspark.broadcast.unpersist",
    "pyspark.cloudpickle.cloudpickle.cell_set",
    "pyspark.cloudpickle.cloudpickle.dynamic_subimport",
    "pyspark.cloudpickle.cloudpickle.instance",
    "pyspark.cloudpickle.cloudpickle.is_tornado_coroutine",
    "pyspark.cloudpickle.cloudpickle.list_registry_pickle_by_value",
    "pyspark.cloudpickle.cloudpickle.parametrized_type_hint_getinitargs",
    "pyspark.cloudpickle.cloudpickle.register_pickle_by_value",
    "pyspark.cloudpickle.cloudpickle.subimport",
    "pyspark.cloudpickle.cloudpickle.unregister_pickle_by_value",
    "pyspark.cloudpickle.cloudpickle_fast.dump",
    "pyspark.cloudpickle.cloudpickle_fast.dumps",
    "pyspark.cloudpickle.cloudpickle_fast.reducer_override",
    "pyspark.conf.contains",
    "pyspark.conf.get",
    "pyspark.conf.getAll",
    "pyspark.conf.set",
    "pyspark.conf.setAll",
    "pyspark.conf.setAppName",
    "pyspark.conf.setExecutorEnv",
    "pyspark.conf.setIfMissing",
    "pyspark.conf.setMaster",
    "pyspark.conf.setSparkHome",
    "pyspark.conf.toDebugString",
    "pyspark.context.accumulator",
    "pyspark.context.addArchive",
    "pyspark.context.addFile",
    "pyspark.context.addJobTag",
    "pyspark.context.addPyFile",
    "pyspark.context.binaryFiles",
    "pyspark.context.binaryRecords",
    "pyspark.context.broadcast",
    "pyspark.context.cancelAllJobs",
    "pyspark.context.cancelJobGroup",
    "pyspark.context.cancelJobsWithTag",
    "pyspark.context.clearJobTags",
    "pyspark.context.dump_profiles",
    "pyspark.context.emptyRDD",
    "pyspark.context.getCheckpointDir",
    "pyspark.context.getConf",
    "pyspark.context.getJobTags",
    "pyspark.context.getLocalProperty",
    "pyspark.context.getOrCreate",
    "pyspark.context.hadoopFile",
    "pyspark.context.hadoopRDD",
    "pyspark.context.newAPIHadoopFile",
    "pyspark.context.newAPIHadoopRDD",
    "pyspark.context.parallelize",
    "pyspark.context.pickleFile",
    "pyspark.context.range",
    "pyspark.context.removeJobTag",
    "pyspark.context.runJob",
    "pyspark.context.sequenceFile",
    "pyspark.context.setCheckpointDir",
    "pyspark.context.setInterruptOnCancel",
    "pyspark.context.setJobDescription",
    "pyspark.context.setJobGroup",
    "pyspark.context.setLocalProperty",
    "pyspark.context.setLogLevel",
    "pyspark.context.setSystemProperty",
    "pyspark.context.show_profiles",
    "pyspark.context.sparkUser",
    "pyspark.context.statusTracker",
    "pyspark.context.stop",
    "pyspark.context.textFile",
    "pyspark.context.union",
    "pyspark.context.wholeTextFiles",
    "pyspark.copy_func",
    "pyspark.errors.exceptions.base.getErrorClass",
    "pyspark.errors.exceptions.base.getMessageParameters",
    "pyspark.errors.exceptions.base.getSqlState",
    "pyspark.errors.exceptions.captured.capture_sql_exception",
    "pyspark.errors.exceptions.captured.convert_exception",
    "pyspark.errors.exceptions.captured.getErrorClass",
    "pyspark.errors.exceptions.captured.getMessageParameters",
    "pyspark.errors.exceptions.captured.getSqlState",
    "pyspark.errors.exceptions.captured.install_exception_handler",
    "pyspark.errors.exceptions.captured.unwrap_spark_exception",
    "pyspark.errors.utils.get_error_message",
    "pyspark.errors.utils.get_message_template",
    "pyspark.files.get",
    "pyspark.files.getRootDirectory",
    "pyspark.java_gateway.ensure_callback_server_started",
    "pyspark.java_gateway.launch_gateway",
    "pyspark.java_gateway.local_connect_and_auth",
    "pyspark.join.python_cogroup",
    "pyspark.join.python_full_outer_join",
    "pyspark.join.python_join",
    "pyspark.join.python_left_outer_join",
    "pyspark.join.python_right_outer_join",
    "pyspark.keyword_only",
    "pyspark.profiler.add",
    "pyspark.profiler.addInPlace",
    "pyspark.profiler.add_function",
    "pyspark.profiler.add_profiler",
    "pyspark.profiler.dump",
    "pyspark.profiler.dump_profiles",
    "pyspark.profiler.new_memory_profiler",
    "pyspark.profiler.new_profiler",
    "pyspark.profiler.new_udf_profiler",
    "pyspark.profiler.profile",
    "pyspark.profiler.show",
    "pyspark.profiler.show_profiles",
    "pyspark.profiler.stats",
    "pyspark.profiler.zero",
    "pyspark.rdd.aggregate",
    "pyspark.rdd.aggregateByKey",
    "pyspark.rdd.barrier",
    "pyspark.rdd.cache",
    "pyspark.rdd.cartesian",
    "pyspark.rdd.checkpoint",
    "pyspark.rdd.cleanShuffleDependencies",
    "pyspark.rdd.coalesce",
    "pyspark.rdd.cogroup",
    "pyspark.rdd.collect",
    "pyspark.rdd.collectAsMap",
    "pyspark.rdd.collectWithJobGroup",
    "pyspark.rdd.combineByKey",
    "pyspark.rdd.count",
    "pyspark.rdd.countApprox",
    "pyspark.rdd.countApproxDistinct",
    "pyspark.rdd.countByKey",
    "pyspark.rdd.countByValue",
    "pyspark.rdd.distinct",
    "pyspark.rdd.filter",
    "pyspark.rdd.first",
    "pyspark.rdd.flatMap",
    "pyspark.rdd.flatMapValues",
    "pyspark.rdd.fold",
    "pyspark.rdd.foldByKey",
    "pyspark.rdd.foreach",
    "pyspark.rdd.foreachPartition",
    "pyspark.rdd.fullOuterJoin",
    "pyspark.rdd.getCheckpointFile",
    "pyspark.rdd.getNumPartitions",
    "pyspark.rdd.getResourceProfile",
    "pyspark.rdd.getStorageLevel",
    "pyspark.rdd.glom",
    "pyspark.rdd.groupBy",
    "pyspark.rdd.groupByKey",
    "pyspark.rdd.groupWith",
    "pyspark.rdd.histogram",
    "pyspark.rdd.id",
    "pyspark.rdd.intersection",
    "pyspark.rdd.isCheckpointed",
    "pyspark.rdd.isEmpty",
    "pyspark.rdd.isLocallyCheckpointed",
    "pyspark.rdd.join",
    "pyspark.rdd.keyBy",
    "pyspark.rdd.keys",
    "pyspark.rdd.leftOuterJoin",
    "pyspark.rdd.localCheckpoint",
    "pyspark.rdd.lookup",
    "pyspark.rdd.map",
    "pyspark.rdd.mapPartitions",
    "pyspark.rdd.mapPartitionsWithIndex",
    "pyspark.rdd.mapPartitionsWithSplit",
    "pyspark.rdd.mapValues",
    "pyspark.rdd.max",
    "pyspark.rdd.mean",
    "pyspark.rdd.meanApprox",
    "pyspark.rdd.min",
    "pyspark.rdd.name",
    "pyspark.rdd.partitionBy",
    "pyspark.rdd.persist",
    "pyspark.rdd.pipe",
    "pyspark.rdd.portable_hash",
    "pyspark.rdd.randomSplit",
    "pyspark.rdd.reduce",
    "pyspark.rdd.reduceByKey",
    "pyspark.rdd.reduceByKeyLocally",
    "pyspark.rdd.repartition",
    "pyspark.rdd.repartitionAndSortWithinPartitions",
    "pyspark.rdd.rightOuterJoin",
    "pyspark.rdd.sample",
    "pyspark.rdd.sampleByKey",
    "pyspark.rdd.sampleStdev",
    "pyspark.rdd.sampleVariance",
    "pyspark.rdd.saveAsHadoopDataset",
    "pyspark.rdd.saveAsHadoopFile",
    "pyspark.rdd.saveAsNewAPIHadoopDataset",
    "pyspark.rdd.saveAsNewAPIHadoopFile",
    "pyspark.rdd.saveAsPickleFile",
    "pyspark.rdd.saveAsSequenceFile",
    "pyspark.rdd.saveAsTextFile",
    "pyspark.rdd.setName",
    "pyspark.rdd.sortBy",
    "pyspark.rdd.sortByKey",
    "pyspark.rdd.stats",
    "pyspark.rdd.stdev",
    "pyspark.rdd.subtract",
    "pyspark.rdd.subtractByKey",
    "pyspark.rdd.sum",
    "pyspark.rdd.sumApprox",
    "pyspark.rdd.take",
    "pyspark.rdd.takeOrdered",
    "pyspark.rdd.takeSample",
    "pyspark.rdd.toDF",
    "pyspark.rdd.toDebugString",
    "pyspark.rdd.toLocalIterator",
    "pyspark.rdd.top",
    "pyspark.rdd.treeAggregate",
    "pyspark.rdd.treeReduce",
    "pyspark.rdd.union",
    "pyspark.rdd.unpersist",
    "pyspark.rdd.values",
    "pyspark.rdd.variance",
    "pyspark.rdd.withResources",
    "pyspark.rdd.zip",
    "pyspark.rdd.zipWithIndex",
    "pyspark.rdd.zipWithUniqueId",
    "pyspark.rddsampler.func",
    "pyspark.rddsampler.getPoissonSample",
    "pyspark.rddsampler.getUniformSample",
    "pyspark.rddsampler.initRandomGenerator",
    "pyspark.resource.profile.clearExecutorResourceRequests",
    "pyspark.resource.profile.clearTaskResourceRequests",
    "pyspark.resource.profile.require",
    "pyspark.resource.requests.cores",
    "pyspark.resource.requests.cpus",
    "pyspark.resource.requests.memory",
    "pyspark.resource.requests.memoryOverhead",
    "pyspark.resource.requests.offheapMemory",
    "pyspark.resource.requests.pysparkMemory",
    "pyspark.resource.requests.resource",
    "pyspark.serializers.close",
    "pyspark.serializers.dump_stream",
    "pyspark.serializers.dumps",
    "pyspark.serializers.load_stream",
    "pyspark.serializers.loads",
    "pyspark.serializers.pack_long",
    "pyspark.serializers.read_bool",
    "pyspark.serializers.read_int",
    "pyspark.serializers.read_long",
    "pyspark.serializers.write",
    "pyspark.serializers.write_int",
    "pyspark.serializers.write_long",
    "pyspark.serializers.write_with_length",
    "pyspark.shuffle.append",
    "pyspark.shuffle.flattened_serializer",
    "pyspark.shuffle.get_used_memory",
    "pyspark.shuffle.items",
    "pyspark.shuffle.mergeCombiners",
    "pyspark.shuffle.mergeValues",
    "pyspark.shuffle.sorted",
    "pyspark.since",
    "pyspark.sql.catalog.cacheTable",
    "pyspark.sql.catalog.clearCache",
    "pyspark.sql.catalog.createExternalTable",
    "pyspark.sql.catalog.createTable",
    "pyspark.sql.catalog.currentCatalog",
    "pyspark.sql.catalog.currentDatabase",
    "pyspark.sql.catalog.databaseExists",
    "pyspark.sql.catalog.dropGlobalTempView",
    "pyspark.sql.catalog.dropTempView",
    "pyspark.sql.catalog.functionExists",
    "pyspark.sql.catalog.getDatabase",
    "pyspark.sql.catalog.getFunction",
    "pyspark.sql.catalog.getTable",
    "pyspark.sql.catalog.isCached",
    "pyspark.sql.catalog.listCatalogs",
    "pyspark.sql.catalog.listColumns",
    "pyspark.sql.catalog.listDatabases",
    "pyspark.sql.catalog.listFunctions",
    "pyspark.sql.catalog.listTables",
    "pyspark.sql.catalog.recoverPartitions",
    "pyspark.sql.catalog.refreshByPath",
    "pyspark.sql.catalog.refreshTable",
    "pyspark.sql.catalog.registerFunction",
    "pyspark.sql.catalog.setCurrentCatalog",
    "pyspark.sql.catalog.setCurrentDatabase",
    "pyspark.sql.catalog.tableExists",
    "pyspark.sql.catalog.uncacheTable",
    "pyspark.sql.column.alias",
    "pyspark.sql.column.asc",
    "pyspark.sql.column.asc_nulls_first",
    "pyspark.sql.column.asc_nulls_last",
    "pyspark.sql.column.astype",
    "pyspark.sql.column.between",
    "pyspark.sql.column.bitwiseAND",
    "pyspark.sql.column.bitwiseOR",
    "pyspark.sql.column.bitwiseXOR",
    "pyspark.sql.column.cast",
    "pyspark.sql.column.contains",
    "pyspark.sql.column.desc",
    "pyspark.sql.column.desc_nulls_first",
    "pyspark.sql.column.desc_nulls_last",
    "pyspark.sql.column.dropFields",
    "pyspark.sql.column.endswith",
    "pyspark.sql.column.eqNullSafe",
    "pyspark.sql.column.getField",
    "pyspark.sql.column.getItem",
    "pyspark.sql.column.ilike",
    "pyspark.sql.column.isNotNull",
    "pyspark.sql.column.isNull",
    "pyspark.sql.column.isin",
    "pyspark.sql.column.like",
    "pyspark.sql.column.name",
    "pyspark.sql.column.otherwise",
    "pyspark.sql.column.over",
    "pyspark.sql.column.rlike",
    "pyspark.sql.column.startswith",
    "pyspark.sql.column.substr",
    "pyspark.sql.column.when",
    "pyspark.sql.column.withField",
    "pyspark.sql.conf.get",
    "pyspark.sql.conf.isModifiable",
    "pyspark.sql.conf.set",
    "pyspark.sql.conf.unset",
    "pyspark.sql.context.cacheTable",
    "pyspark.sql.context.clearCache",
    "pyspark.sql.context.createDataFrame",
    "pyspark.sql.context.createExternalTable",
    "pyspark.sql.context.dropTempTable",
    "pyspark.sql.context.getConf",
    "pyspark.sql.context.getOrCreate",
    "pyspark.sql.context.newSession",
    "pyspark.sql.context.range",
    "pyspark.sql.context.refreshTable",
    "pyspark.sql.context.registerDataFrameAsTable",
    "pyspark.sql.context.registerFunction",
    "pyspark.sql.context.registerJavaFunction",
    "pyspark.sql.context.setConf",
    "pyspark.sql.context.sql",
    "pyspark.sql.context.table",
    "pyspark.sql.context.tableNames",
    "pyspark.sql.context.tables",
    "pyspark.sql.context.uncacheTable",
    "pyspark.sql.dataframe.agg",
    "pyspark.sql.dataframe.alias",
    "pyspark.sql.dataframe.approxQuantile",
    "pyspark.sql.dataframe.cache",
    "pyspark.sql.dataframe.checkpoint",
    "pyspark.sql.dataframe.coalesce",
    "pyspark.sql.dataframe.colRegex",
    "pyspark.sql.dataframe.collect",
    "pyspark.sql.dataframe.corr",
    "pyspark.sql.dataframe.count",
    "pyspark.sql.dataframe.cov",
    "pyspark.sql.dataframe.createGlobalTempView",
    "pyspark.sql.dataframe.createOrReplaceGlobalTempView",
    "pyspark.sql.dataframe.createOrReplaceTempView",
    "pyspark.sql.dataframe.createTempView",
    "pyspark.sql.dataframe.crossJoin",
    "pyspark.sql.dataframe.crosstab",
    "pyspark.sql.dataframe.cube",
    "pyspark.sql.dataframe.describe",
    "pyspark.sql.dataframe.distinct",
    "pyspark.sql.dataframe.drop",
    "pyspark.sql.dataframe.dropDuplicates",
    "pyspark.sql.dataframe.dropDuplicatesWithinWatermark",
    "pyspark.sql.dataframe.drop_duplicates",
    "pyspark.sql.dataframe.dropna",
    "pyspark.sql.dataframe.exceptAll",
    "pyspark.sql.dataframe.explain",
    "pyspark.sql.dataframe.fill",
    "pyspark.sql.dataframe.fillna",
    "pyspark.sql.dataframe.filter",
    "pyspark.sql.dataframe.first",
    "pyspark.sql.dataframe.foreach",
    "pyspark.sql.dataframe.foreachPartition",
    "pyspark.sql.dataframe.freqItems",
    "pyspark.sql.dataframe.groupBy",
    "pyspark.sql.dataframe.groupby",
    "pyspark.sql.dataframe.head",
    "pyspark.sql.dataframe.hint",
    "pyspark.sql.dataframe.inputFiles",
    "pyspark.sql.dataframe.intersect",
    "pyspark.sql.dataframe.intersectAll",
    "pyspark.sql.dataframe.isEmpty",
    "pyspark.sql.dataframe.isLocal",
    "pyspark.sql.dataframe.join",
    "pyspark.sql.dataframe.limit",
    "pyspark.sql.dataframe.localCheckpoint",
    "pyspark.sql.dataframe.melt",
    "pyspark.sql.dataframe.observe",
    "pyspark.sql.dataframe.offset",
    "pyspark.sql.dataframe.orderBy",
    "pyspark.sql.dataframe.pandas_api",
    "pyspark.sql.dataframe.persist",
    "pyspark.sql.dataframe.printSchema",
    "pyspark.sql.dataframe.randomSplit",
    "pyspark.sql.dataframe.registerTempTable",
    "pyspark.sql.dataframe.repartition",
    "pyspark.sql.dataframe.repartitionByRange",
    "pyspark.sql.dataframe.replace",
    "pyspark.sql.dataframe.rollup",
    "pyspark.sql.dataframe.sameSemantics",
    "pyspark.sql.dataframe.sample",
    "pyspark.sql.dataframe.sampleBy",
    "pyspark.sql.dataframe.select",
    "pyspark.sql.dataframe.selectExpr",
    "pyspark.sql.dataframe.semanticHash",
    "pyspark.sql.dataframe.show",
    "pyspark.sql.dataframe.sort",
    "pyspark.sql.dataframe.sortWithinPartitions",
    "pyspark.sql.dataframe.subtract",
    "pyspark.sql.dataframe.summary",
    "pyspark.sql.dataframe.tail",
    "pyspark.sql.dataframe.take",
    "pyspark.sql.dataframe.to",
    "pyspark.sql.dataframe.toDF",
    "pyspark.sql.dataframe.toJSON",
    "pyspark.sql.dataframe.toLocalIterator",
    "pyspark.sql.dataframe.to_koalas",
    "pyspark.sql.dataframe.to_pandas_on_spark",
    "pyspark.sql.dataframe.transform",
    "pyspark.sql.dataframe.union",
    "pyspark.sql.dataframe.unionAll",
    "pyspark.sql.dataframe.unionByName",
    "pyspark.sql.dataframe.unpersist",
    "pyspark.sql.dataframe.unpivot",
    "pyspark.sql.dataframe.where",
    "pyspark.sql.dataframe.withColumn",
    "pyspark.sql.dataframe.withColumnRenamed",
    "pyspark.sql.dataframe.withColumns",
    "pyspark.sql.dataframe.withColumnsRenamed",
    "pyspark.sql.dataframe.withMetadata",
    "pyspark.sql.dataframe.withWatermark",
    "pyspark.sql.dataframe.writeTo",
    "pyspark.sql.functions.abs",
    "pyspark.sql.functions.acos",
    "pyspark.sql.functions.acosh",
    "pyspark.sql.functions.add_months",
    "pyspark.sql.functions.aes_decrypt",
    "pyspark.sql.functions.aes_encrypt",
    "pyspark.sql.functions.aggregate",
    "pyspark.sql.functions.any_value",
    "pyspark.sql.functions.approxCountDistinct",
    "pyspark.sql.functions.approx_count_distinct",
    "pyspark.sql.functions.approx_percentile",
    "pyspark.sql.functions.array",
    "pyspark.sql.functions.array_agg",
    "pyspark.sql.functions.array_append",
    "pyspark.sql.functions.array_compact",
    "pyspark.sql.functions.array_contains",
    "pyspark.sql.functions.array_distinct",
    "pyspark.sql.functions.array_except",
    "pyspark.sql.functions.array_insert",
    "pyspark.sql.functions.array_intersect",
    "pyspark.sql.functions.array_join",
    "pyspark.sql.functions.array_max",
    "pyspark.sql.functions.array_min",
    "pyspark.sql.functions.array_position",
    "pyspark.sql.functions.array_prepend",
    "pyspark.sql.functions.array_remove",
    "pyspark.sql.functions.array_repeat",
    "pyspark.sql.functions.array_size",
    "pyspark.sql.functions.array_sort",
    "pyspark.sql.functions.array_union",
    "pyspark.sql.functions.arrays_overlap",
    "pyspark.sql.functions.arrays_zip",
    "pyspark.sql.functions.asc",
    "pyspark.sql.functions.asc_nulls_first",
    "pyspark.sql.functions.asc_nulls_last",
    "pyspark.sql.functions.ascii",
    "pyspark.sql.functions.asin",
    "pyspark.sql.functions.asinh",
    "pyspark.sql.functions.assert_true",
    "pyspark.sql.functions.atan",
    "pyspark.sql.functions.atan2",
    "pyspark.sql.functions.atanh",
    "pyspark.sql.functions.avg",
    "pyspark.sql.functions.base64",
    "pyspark.sql.functions.bin",
    "pyspark.sql.functions.bit_and",
    "pyspark.sql.functions.bit_count",
    "pyspark.sql.functions.bit_get",
    "pyspark.sql.functions.bit_length",
    "pyspark.sql.functions.bit_or",
    "pyspark.sql.functions.bit_xor",
    "pyspark.sql.functions.bitmap_bit_position",
    "pyspark.sql.functions.bitmap_bucket_number",
    "pyspark.sql.functions.bitmap_construct_agg",
    "pyspark.sql.functions.bitmap_count",
    "pyspark.sql.functions.bitmap_or_agg",
    "pyspark.sql.functions.bitwiseNOT",
    "pyspark.sql.functions.bitwise_not",
    "pyspark.sql.functions.bool_and",
    "pyspark.sql.functions.bool_or",
    "pyspark.sql.functions.broadcast",
    "pyspark.sql.functions.bround",
    "pyspark.sql.functions.btrim",
    "pyspark.sql.functions.bucket",
    "pyspark.sql.functions.call_function",
    "pyspark.sql.functions.call_udf",
    "pyspark.sql.functions.cardinality",
    "pyspark.sql.functions.cbrt",
    "pyspark.sql.functions.ceil",
    "pyspark.sql.functions.ceiling",
    "pyspark.sql.functions.char",
    "pyspark.sql.functions.char_length",
    "pyspark.sql.functions.character_length",
    "pyspark.sql.functions.coalesce",
    "pyspark.sql.functions.col",
    "pyspark.sql.functions.collect_list",
    "pyspark.sql.functions.collect_set",
    "pyspark.sql.functions.column",
    "pyspark.sql.functions.concat",
    "pyspark.sql.functions.concat_ws",
    "pyspark.sql.functions.contains",
    "pyspark.sql.functions.conv",
    "pyspark.sql.functions.convert_timezone",
    "pyspark.sql.functions.corr",
    "pyspark.sql.functions.cos",
    "pyspark.sql.functions.cosh",
    "pyspark.sql.functions.cot",
    "pyspark.sql.functions.count",
    "pyspark.sql.functions.countDistinct",
    "pyspark.sql.functions.count_distinct",
    "pyspark.sql.functions.count_if",
    "pyspark.sql.functions.count_min_sketch",
    "pyspark.sql.functions.covar_pop",
    "pyspark.sql.functions.covar_samp",
    "pyspark.sql.functions.crc32",
    "pyspark.sql.functions.create_map",
    "pyspark.sql.functions.csc",
    "pyspark.sql.functions.cume_dist",
    "pyspark.sql.functions.curdate",
    "pyspark.sql.functions.current_catalog",
    "pyspark.sql.functions.current_database",
    "pyspark.sql.functions.current_date",
    "pyspark.sql.functions.current_schema",
    "pyspark.sql.functions.current_timestamp",
    "pyspark.sql.functions.current_timezone",
    "pyspark.sql.functions.current_user",
    "pyspark.sql.functions.date_add",
    "pyspark.sql.functions.date_diff",
    "pyspark.sql.functions.date_format",
    "pyspark.sql.functions.date_from_unix_date",
    "pyspark.sql.functions.date_part",
    "pyspark.sql.functions.date_sub",
    "pyspark.sql.functions.date_trunc",
    "pyspark.sql.functions.dateadd",
    "pyspark.sql.functions.datediff",
    "pyspark.sql.functions.datepart",
    "pyspark.sql.functions.day",
    "pyspark.sql.functions.dayofmonth",
    "pyspark.sql.functions.dayofweek",
    "pyspark.sql.functions.dayofyear",
    "pyspark.sql.functions.days",
    "pyspark.sql.functions.decode",
    "pyspark.sql.functions.degrees",
    "pyspark.sql.functions.dense_rank",
    "pyspark.sql.functions.desc",
    "pyspark.sql.functions.desc_nulls_first",
    "pyspark.sql.functions.desc_nulls_last",
    "pyspark.sql.functions.e",
    "pyspark.sql.functions.element_at",
    "pyspark.sql.functions.elt",
    "pyspark.sql.functions.encode",
    "pyspark.sql.functions.endswith",
    "pyspark.sql.functions.equal_null",
    "pyspark.sql.functions.every",
    "pyspark.sql.functions.exists",
    "pyspark.sql.functions.exp",
    "pyspark.sql.functions.explode",
    "pyspark.sql.functions.explode_outer",
    "pyspark.sql.functions.expm1",
    "pyspark.sql.functions.expr",
    "pyspark.sql.functions.extract",
    "pyspark.sql.functions.factorial",
    "pyspark.sql.functions.filter",
    "pyspark.sql.functions.find_in_set",
    "pyspark.sql.functions.first",
    "pyspark.sql.functions.first_value",
    "pyspark.sql.functions.flatten",
    "pyspark.sql.functions.floor",
    "pyspark.sql.functions.forall",
    "pyspark.sql.functions.format_number",
    "pyspark.sql.functions.format_string",
    "pyspark.sql.functions.from_csv",
    "pyspark.sql.functions.from_json",
    "pyspark.sql.functions.from_unixtime",
    "pyspark.sql.functions.from_utc_timestamp",
    "pyspark.sql.functions.get",
    "pyspark.sql.functions.get_json_object",
    "pyspark.sql.functions.getbit",
    "pyspark.sql.functions.greatest",
    "pyspark.sql.functions.grouping",
    "pyspark.sql.functions.grouping_id",
    "pyspark.sql.functions.hash",
    "pyspark.sql.functions.hex",
    "pyspark.sql.functions.histogram_numeric",
    "pyspark.sql.functions.hll_sketch_agg",
    "pyspark.sql.functions.hll_sketch_estimate",
    "pyspark.sql.functions.hll_union",
    "pyspark.sql.functions.hll_union_agg",
    "pyspark.sql.functions.hour",
    "pyspark.sql.functions.hours",
    "pyspark.sql.functions.hypot",
    "pyspark.sql.functions.ifnull",
    "pyspark.sql.functions.ilike",
    "pyspark.sql.functions.initcap",
    "pyspark.sql.functions.inline",
    "pyspark.sql.functions.inline_outer",
    "pyspark.sql.functions.input_file_block_length",
    "pyspark.sql.functions.input_file_block_start",
    "pyspark.sql.functions.input_file_name",
    "pyspark.sql.functions.instr",
    "pyspark.sql.functions.isnan",
    "pyspark.sql.functions.isnotnull",
    "pyspark.sql.functions.isnull",
    "pyspark.sql.functions.java_method",
    "pyspark.sql.functions.json_array_length",
    "pyspark.sql.functions.json_object_keys",
    "pyspark.sql.functions.json_tuple",
    "pyspark.sql.functions.kurtosis",
    "pyspark.sql.functions.lag",
    "pyspark.sql.functions.last",
    "pyspark.sql.functions.last_day",
    "pyspark.sql.functions.last_value",
    "pyspark.sql.functions.lcase",
    "pyspark.sql.functions.lead",
    "pyspark.sql.functions.least",
    "pyspark.sql.functions.left",
    "pyspark.sql.functions.length",
    "pyspark.sql.functions.levenshtein",
    "pyspark.sql.functions.like",
    "pyspark.sql.functions.lit",
    "pyspark.sql.functions.ln",
    "pyspark.sql.functions.localtimestamp",
    "pyspark.sql.functions.locate",
    "pyspark.sql.functions.log",
    "pyspark.sql.functions.log10",
    "pyspark.sql.functions.log1p",
    "pyspark.sql.functions.log2",
    "pyspark.sql.functions.lower",
    "pyspark.sql.functions.lpad",
    "pyspark.sql.functions.ltrim",
    "pyspark.sql.functions.make_date",
    "pyspark.sql.functions.make_dt_interval",
    "pyspark.sql.functions.make_interval",
    "pyspark.sql.functions.make_timestamp",
    "pyspark.sql.functions.make_timestamp_ltz",
    "pyspark.sql.functions.make_timestamp_ntz",
    "pyspark.sql.functions.make_ym_interval",
    "pyspark.sql.functions.map_concat",
    "pyspark.sql.functions.map_contains_key",
    "pyspark.sql.functions.map_entries",
    "pyspark.sql.functions.map_filter",
    "pyspark.sql.functions.map_from_arrays",
    "pyspark.sql.functions.map_from_entries",
    "pyspark.sql.functions.map_keys",
    "pyspark.sql.functions.map_values",
    "pyspark.sql.functions.map_zip_with",
    "pyspark.sql.functions.mask",
    "pyspark.sql.functions.max",
    "pyspark.sql.functions.max_by",
    "pyspark.sql.functions.md5",
    "pyspark.sql.functions.mean",
    "pyspark.sql.functions.median",
    "pyspark.sql.functions.min",
    "pyspark.sql.functions.min_by",
    "pyspark.sql.functions.minute",
    "pyspark.sql.functions.mode",
    "pyspark.sql.functions.monotonically_increasing_id",
    "pyspark.sql.functions.month",
    "pyspark.sql.functions.months",
    "pyspark.sql.functions.months_between",
    "pyspark.sql.functions.named_struct",
    "pyspark.sql.functions.nanvl",
    "pyspark.sql.functions.negate",
    "pyspark.sql.functions.negative",
    "pyspark.sql.functions.next_day",
    "pyspark.sql.functions.now",
    "pyspark.sql.functions.nth_value",
    "pyspark.sql.functions.ntile",
    "pyspark.sql.functions.nullif",
    "pyspark.sql.functions.nvl",
    "pyspark.sql.functions.nvl2",
    "pyspark.sql.functions.octet_length",
    "pyspark.sql.functions.overlay",
    "pyspark.sql.functions.parse_url",
    "pyspark.sql.functions.percent_rank",
    "pyspark.sql.functions.percentile",
    "pyspark.sql.functions.percentile_approx",
    "pyspark.sql.functions.pi",
    "pyspark.sql.functions.pmod",
    "pyspark.sql.functions.posexplode",
    "pyspark.sql.functions.posexplode_outer",
    "pyspark.sql.functions.position",
    "pyspark.sql.functions.positive",
    "pyspark.sql.functions.pow",
    "pyspark.sql.functions.power",
    "pyspark.sql.functions.printf",
    "pyspark.sql.functions.product",
    "pyspark.sql.functions.quarter",
    "pyspark.sql.functions.radians",
    "pyspark.sql.functions.raise_error",
    "pyspark.sql.functions.rand",
    "pyspark.sql.functions.randn",
    "pyspark.sql.functions.rank",
    "pyspark.sql.functions.reduce",
    "pyspark.sql.functions.reflect",
    "pyspark.sql.functions.regexp",
    "pyspark.sql.functions.regexp_count",
    "pyspark.sql.functions.regexp_extract",
    "pyspark.sql.functions.regexp_extract_all",
    "pyspark.sql.functions.regexp_instr",
    "pyspark.sql.functions.regexp_like",
    "pyspark.sql.functions.regexp_replace",
    "pyspark.sql.functions.regexp_substr",
    "pyspark.sql.functions.regr_avgx",
    "pyspark.sql.functions.regr_avgy",
    "pyspark.sql.functions.regr_count",
    "pyspark.sql.functions.regr_intercept",
    "pyspark.sql.functions.regr_r2",
    "pyspark.sql.functions.regr_slope",
    "pyspark.sql.functions.regr_sxx",
    "pyspark.sql.functions.regr_sxy",
    "pyspark.sql.functions.regr_syy",
    "pyspark.sql.functions.repeat",
    "pyspark.sql.functions.replace",
    "pyspark.sql.functions.reverse",
    "pyspark.sql.functions.right",
    "pyspark.sql.functions.rint",
    "pyspark.sql.functions.rlike",
    "pyspark.sql.functions.round",
    "pyspark.sql.functions.row_number",
    "pyspark.sql.functions.rpad",
    "pyspark.sql.functions.rtrim",
    "pyspark.sql.functions.schema_of_csv",
    "pyspark.sql.functions.schema_of_json",
    "pyspark.sql.functions.sec",
    "pyspark.sql.functions.second",
    "pyspark.sql.functions.sentences",
    "pyspark.sql.functions.sequence",
    "pyspark.sql.functions.session_window",
    "pyspark.sql.functions.sha",
    "pyspark.sql.functions.sha1",
    "pyspark.sql.functions.sha2",
    "pyspark.sql.functions.shiftLeft",
    "pyspark.sql.functions.shiftRight",
    "pyspark.sql.functions.shiftRightUnsigned",
    "pyspark.sql.functions.shiftleft",
    "pyspark.sql.functions.shiftright",
    "pyspark.sql.functions.shiftrightunsigned",
    "pyspark.sql.functions.shuffle",
    "pyspark.sql.functions.sign",
    "pyspark.sql.functions.signum",
    "pyspark.sql.functions.sin",
    "pyspark.sql.functions.sinh",
    "pyspark.sql.functions.size",
    "pyspark.sql.functions.skewness",
    "pyspark.sql.functions.slice",
    "pyspark.sql.functions.some",
    "pyspark.sql.functions.sort_array",
    "pyspark.sql.functions.soundex",
    "pyspark.sql.functions.spark_partition_id",
    "pyspark.sql.functions.split",
    "pyspark.sql.functions.split_part",
    "pyspark.sql.functions.sqrt",
    "pyspark.sql.functions.stack",
    "pyspark.sql.functions.startswith",
    "pyspark.sql.functions.std",
    "pyspark.sql.functions.stddev",
    "pyspark.sql.functions.stddev_pop",
    "pyspark.sql.functions.stddev_samp",
    "pyspark.sql.functions.str_to_map",
    "pyspark.sql.functions.struct",
    "pyspark.sql.functions.substr",
    "pyspark.sql.functions.substring",
    "pyspark.sql.functions.substring_index",
    "pyspark.sql.functions.sum",
    "pyspark.sql.functions.sumDistinct",
    "pyspark.sql.functions.sum_distinct",
    "pyspark.sql.functions.tan",
    "pyspark.sql.functions.tanh",
    "pyspark.sql.functions.timestamp_micros",
    "pyspark.sql.functions.timestamp_millis",
    "pyspark.sql.functions.timestamp_seconds",
    "pyspark.sql.functions.toDegrees",
    "pyspark.sql.functions.toRadians",
    "pyspark.sql.functions.to_binary",
    "pyspark.sql.functions.to_char",
    "pyspark.sql.functions.to_csv",
    "pyspark.sql.functions.to_date",
    "pyspark.sql.functions.to_json",
    "pyspark.sql.functions.to_number",
    "pyspark.sql.functions.to_timestamp",
    "pyspark.sql.functions.to_timestamp_ltz",
    "pyspark.sql.functions.to_timestamp_ntz",
    "pyspark.sql.functions.to_unix_timestamp",
    "pyspark.sql.functions.to_utc_timestamp",
    "pyspark.sql.functions.to_varchar",
    "pyspark.sql.functions.transform",
    "pyspark.sql.functions.transform_keys",
    "pyspark.sql.functions.transform_values",
    "pyspark.sql.functions.translate",
    "pyspark.sql.functions.trim",
    "pyspark.sql.functions.trunc",
    "pyspark.sql.functions.try_add",
    "pyspark.sql.functions.try_aes_decrypt",
    "pyspark.sql.functions.try_avg",
    "pyspark.sql.functions.try_divide",
    "pyspark.sql.functions.try_element_at",
    "pyspark.sql.functions.try_multiply",
    "pyspark.sql.functions.try_subtract",
    "pyspark.sql.functions.try_sum",
    "pyspark.sql.functions.try_to_binary",
    "pyspark.sql.functions.try_to_number",
    "pyspark.sql.functions.try_to_timestamp",
    "pyspark.sql.functions.typeof",
    "pyspark.sql.functions.ucase",
    "pyspark.sql.functions.udf",
    "pyspark.sql.functions.udtf",
    "pyspark.sql.functions.unbase64",
    "pyspark.sql.functions.unhex",
    "pyspark.sql.functions.unix_date",
    "pyspark.sql.functions.unix_micros",
    "pyspark.sql.functions.unix_millis",
    "pyspark.sql.functions.unix_seconds",
    "pyspark.sql.functions.unix_timestamp",
    "pyspark.sql.functions.unwrap_udt",
    "pyspark.sql.functions.upper",
    "pyspark.sql.functions.url_decode",
    "pyspark.sql.functions.url_encode",
    "pyspark.sql.functions.user",
    "pyspark.sql.functions.var_pop",
    "pyspark.sql.functions.var_samp",
    "pyspark.sql.functions.variance",
    "pyspark.sql.functions.version",
    "pyspark.sql.functions.weekday",
    "pyspark.sql.functions.weekofyear",
    "pyspark.sql.functions.when",
    "pyspark.sql.functions.width_bucket",
    "pyspark.sql.functions.window",
    "pyspark.sql.functions.window_time",
    "pyspark.sql.functions.xpath",
    "pyspark.sql.functions.xpath_boolean",
    "pyspark.sql.functions.xpath_double",
    "pyspark.sql.functions.xpath_float",
    "pyspark.sql.functions.xpath_int",
    "pyspark.sql.functions.xpath_long",
    "pyspark.sql.functions.xpath_number",
    "pyspark.sql.functions.xpath_short",
    "pyspark.sql.functions.xpath_string",
    "pyspark.sql.functions.xxhash64",
    "pyspark.sql.functions.year",
    "pyspark.sql.functions.years",
    "pyspark.sql.functions.zip_with",
    "pyspark.sql.group.agg",
    "pyspark.sql.group.avg",
    "pyspark.sql.group.count",
    "pyspark.sql.group.df_varargs_api",
    "pyspark.sql.group.dfapi",
    "pyspark.sql.group.max",
    "pyspark.sql.group.mean",
    "pyspark.sql.group.min",
    "pyspark.sql.group.pivot",
    "pyspark.sql.group.sum",
    "pyspark.sql.pandas.conversion.createDataFrame",
    "pyspark.sql.pandas.conversion.toPandas",
    "pyspark.sql.pandas.functions.pandas_udf",
    "pyspark.sql.pandas.group_ops.apply",
    "pyspark.sql.pandas.group_ops.applyInPandas",
    "pyspark.sql.pandas.group_ops.applyInPandasWithState",
    "pyspark.sql.pandas.group_ops.cogroup",
    "pyspark.sql.pandas.map_ops.mapInArrow",
    "pyspark.sql.pandas.map_ops.mapInPandas",
    "pyspark.sql.pandas.serializers.arrow_to_pandas",
    "pyspark.sql.pandas.serializers.dump_stream",
    "pyspark.sql.pandas.serializers.load_stream",
    "pyspark.sql.pandas.typehints.check_iterator_annotation",
    "pyspark.sql.pandas.typehints.check_tuple_annotation",
    "pyspark.sql.pandas.typehints.check_union_annotation",
    "pyspark.sql.pandas.typehints.infer_eval_type",
    "pyspark.sql.pandas.types.from_arrow_schema",
    "pyspark.sql.pandas.types.from_arrow_type",
    "pyspark.sql.pandas.types.to_arrow_schema",
    "pyspark.sql.pandas.types.to_arrow_type",
    "pyspark.sql.pandas.utils.pyarrow_version_less_than_minimum",
    "pyspark.sql.pandas.utils.require_minimum_pandas_version",
    "pyspark.sql.pandas.utils.require_minimum_pyarrow_version",
    "pyspark.sql.readwriter.append",
    "pyspark.sql.readwriter.bucketBy",
    "pyspark.sql.readwriter.create",
    "pyspark.sql.readwriter.createOrReplace",
    "pyspark.sql.readwriter.csv",
    "pyspark.sql.readwriter.format",
    "pyspark.sql.readwriter.insertInto",
    "pyspark.sql.readwriter.jdbc",
    "pyspark.sql.readwriter.json",
    "pyspark.sql.readwriter.load",
    "pyspark.sql.readwriter.mode",
    "pyspark.sql.readwriter.option",
    "pyspark.sql.readwriter.options",
    "pyspark.sql.readwriter.orc",
    "pyspark.sql.readwriter.overwrite",
    "pyspark.sql.readwriter.overwritePartitions",
    "pyspark.sql.readwriter.parquet",
    "pyspark.sql.readwriter.partitionBy",
    "pyspark.sql.readwriter.partitionedBy",
    "pyspark.sql.readwriter.replace",
    "pyspark.sql.readwriter.save",
    "pyspark.sql.readwriter.saveAsTable",
    "pyspark.sql.readwriter.schema",
    "pyspark.sql.readwriter.sortBy",
    "pyspark.sql.readwriter.table",
    "pyspark.sql.readwriter.tableProperty",
    "pyspark.sql.readwriter.text",
    "pyspark.sql.readwriter.using",
    "pyspark.sql.session.active",
    "pyspark.sql.session.addArtifact",
    "pyspark.sql.session.addArtifacts",
    "pyspark.sql.session.addTag",
    "pyspark.sql.session.appName",
    "pyspark.sql.session.clearTags",
    "pyspark.sql.session.config",
    "pyspark.sql.session.copyFromLocalToFs",
    "pyspark.sql.session.create",
    "pyspark.sql.session.createDataFrame",
    "pyspark.sql.session.enableHiveSupport",
    "pyspark.sql.session.getActiveSession",
    "pyspark.sql.session.getOrCreate",
    "pyspark.sql.session.getTags",
    "pyspark.sql.session.interruptAll",
    "pyspark.sql.session.interruptOperation",
    "pyspark.sql.session.interruptTag",
    "pyspark.sql.session.master",
    "pyspark.sql.session.newSession",
    "pyspark.sql.session.range",
    "pyspark.sql.session.remote",
    "pyspark.sql.session.removeTag",
    "pyspark.sql.session.sql",
    "pyspark.sql.session.stop",
    "pyspark.sql.session.table",
    "pyspark.sql.sql_formatter.clear",
    "pyspark.sql.sql_formatter.get_field",
    "pyspark.sql.streaming.listener.fromJObject",
    "pyspark.sql.streaming.listener.fromJson",
    "pyspark.sql.streaming.listener.onQueryIdle",
    "pyspark.sql.streaming.listener.onQueryProgress",
    "pyspark.sql.streaming.listener.onQueryStarted",
    "pyspark.sql.streaming.listener.onQueryTerminated",
    "pyspark.sql.streaming.query.addListener",
    "pyspark.sql.streaming.query.awaitAnyTermination",
    "pyspark.sql.streaming.query.awaitTermination",
    "pyspark.sql.streaming.query.exception",
    "pyspark.sql.streaming.query.explain",
    "pyspark.sql.streaming.query.get",
    "pyspark.sql.streaming.query.processAllAvailable",
    "pyspark.sql.streaming.query.removeListener",
    "pyspark.sql.streaming.query.resetTerminated",
    "pyspark.sql.streaming.query.stop",
    "pyspark.sql.streaming.readwriter.csv",
    "pyspark.sql.streaming.readwriter.foreach",
    "pyspark.sql.streaming.readwriter.foreachBatch",
    "pyspark.sql.streaming.readwriter.format",
    "pyspark.sql.streaming.readwriter.json",
    "pyspark.sql.streaming.readwriter.load",
    "pyspark.sql.streaming.readwriter.option",
    "pyspark.sql.streaming.readwriter.options",
    "pyspark.sql.streaming.readwriter.orc",
    "pyspark.sql.streaming.readwriter.outputMode",
    "pyspark.sql.streaming.readwriter.parquet",
    "pyspark.sql.streaming.readwriter.partitionBy",
    "pyspark.sql.streaming.readwriter.queryName",
    "pyspark.sql.streaming.readwriter.schema",
    "pyspark.sql.streaming.readwriter.start",
    "pyspark.sql.streaming.readwriter.table",
    "pyspark.sql.streaming.readwriter.text",
    "pyspark.sql.streaming.readwriter.toTable",
    "pyspark.sql.streaming.readwriter.trigger",
    "pyspark.sql.streaming.state.getCurrentProcessingTimeMs",
    "pyspark.sql.streaming.state.getCurrentWatermarkMs",
    "pyspark.sql.streaming.state.json",
    "pyspark.sql.streaming.state.remove",
    "pyspark.sql.streaming.state.setTimeoutDuration",
    "pyspark.sql.streaming.state.setTimeoutTimestamp",
    "pyspark.sql.streaming.state.update",
    "pyspark.sql.types.add",
    "pyspark.sql.types.asDict",
    "pyspark.sql.types.can_convert",
    "pyspark.sql.types.convert",
    "pyspark.sql.types.deserialize",
    "pyspark.sql.types.fieldNames",
    "pyspark.sql.types.fromInternal",
    "pyspark.sql.types.fromJson",
    "pyspark.sql.types.json",
    "pyspark.sql.types.jsonValue",
    "pyspark.sql.types.module",
    "pyspark.sql.types.needConversion",
    "pyspark.sql.types.scalaUDT",
    "pyspark.sql.types.serialize",
    "pyspark.sql.types.simpleString",
    "pyspark.sql.types.sqlType",
    "pyspark.sql.types.toInternal",
    "pyspark.sql.types.typeName",
    "pyspark.sql.udf.asNondeterministic",
    "pyspark.sql.udf.register",
    "pyspark.sql.udf.registerJavaFunction",
    "pyspark.sql.udf.registerJavaUDAF",
    "pyspark.sql.udtf.asDeterministic",
    "pyspark.sql.udtf.register",
    "pyspark.sql.utils.call",
    "pyspark.sql.utils.get_active_spark_context",
    "pyspark.sql.utils.get_column_class",
    "pyspark.sql.utils.get_dataframe_class",
    "pyspark.sql.utils.get_window_class",
    "pyspark.sql.utils.is_remote",
    "pyspark.sql.utils.is_timestamp_ntz_preferred",
    "pyspark.sql.utils.pyspark_column_op",
    "pyspark.sql.utils.require_test_compiled",
    "pyspark.sql.utils.toJArray",
    "pyspark.sql.utils.to_str",
    "pyspark.sql.utils.try_remote_avro_functions",
    "pyspark.sql.utils.try_remote_functions",
    "pyspark.sql.utils.try_remote_observation",
    "pyspark.sql.utils.try_remote_protobuf_functions",
    "pyspark.sql.utils.try_remote_session_classmethod",
    "pyspark.sql.utils.try_remote_window",
    "pyspark.sql.utils.try_remote_windowspec",
    "pyspark.sql.window.orderBy",
    "pyspark.sql.window.partitionBy",
    "pyspark.sql.window.rangeBetween",
    "pyspark.sql.window.rowsBetween",
    "pyspark.statcounter.asDict",
    "pyspark.statcounter.copy",
    "pyspark.statcounter.count",
    "pyspark.statcounter.max",
    "pyspark.statcounter.mean",
    "pyspark.statcounter.merge",
    "pyspark.statcounter.mergeStats",
    "pyspark.statcounter.min",
    "pyspark.statcounter.sampleStdev",
    "pyspark.statcounter.sampleVariance",
    "pyspark.statcounter.stdev",
    "pyspark.statcounter.sum",
    "pyspark.statcounter.variance",
    "pyspark.status.getActiveJobsIds",
    "pyspark.status.getActiveStageIds",
    "pyspark.status.getJobIdsForGroup",
    "pyspark.status.getJobInfo",
    "pyspark.status.getStageInfo",
    "pyspark.taskcontext.allGather",
    "pyspark.taskcontext.attemptNumber",
    "pyspark.taskcontext.barrier",
    "pyspark.taskcontext.cpus",
    "pyspark.taskcontext.get",
    "pyspark.taskcontext.getLocalProperty",
    "pyspark.taskcontext.getTaskInfos",
    "pyspark.taskcontext.partitionId",
    "pyspark.taskcontext.resources",
    "pyspark.taskcontext.stageId",
    "pyspark.taskcontext.taskAttemptId",
    "pyspark.traceback_utils.first_spark_call",
    "pyspark.util.fail_on_stopiteration",
    "pyspark.util.inheritable_thread_target",
    "pyspark.util.majorMinorVersion",
    "pyspark.util.print_exec",
    "pyspark.util.start",
    "pyspark.util.try_simplify_traceback",
    "pyspark.util.walk_tb",
    "pysparkMemory",
    "pyspark_column_op",
    "python_cogroup",
    "python_full_outer_join",
    "python_join",
    "python_left_outer_join",
    "python_right_outer_join",
    "quarter",
    "queryName",
    "radians",
    "raise_error",
    "rand",
    "randn",
    "randomSplit",
    "range",
    "rangeBetween",
    "rank",
    "read_bool",
    "read_int",
    "read_long",
    "recoverPartitions",
    "reduce",
    "reduceByKey",
    "reduceByKeyLocally",
    "reducer_override",
    "reflect",
    "refreshByPath",
    "refreshTable",
    "regexp",
    "regexp_count",
    "regexp_extract",
    "regexp_extract_all",
    "regexp_instr",
    "regexp_like",
    "regexp_replace",
    "regexp_substr",
    "register",
    "registerDataFrameAsTable",
    "registerFunction",
    "registerJavaFunction",
    "registerJavaUDAF",
    "registerTempTable",
    "register_input_converter",
    "register_pickle_by_value",
    "regr_avgx",
    "regr_avgy",
    "regr_count",
    "regr_intercept",
    "regr_r2",
    "regr_slope",
    "regr_sxx",
    "regr_sxy",
    "regr_syy",
    "remote",
    "remove",
    "removeJobTag",
    "removeListener",
    "removeTag",
    "repartition",
    "repartitionAndSortWithinPartitions",
    "repartitionByRange",
    "repeat",
    "replace",
    "require",
    "require_minimum_pandas_version",
    "require_minimum_pyarrow_version",
    "require_test_compiled",
    "resetTerminated",
    "resource",
    "resources",
    "reverse",
    "right",
    "rightOuterJoin",
    "rint",
    "rlike",
    "rollup",
    "round",
    "row_number",
    "rowsBetween",
    "rpad",
    "rtrim",
    "run",
    "runJob",
    "runctx",
    "sameSemantics",
    "sample",
    "sampleBy",
    "sampleByKey",
    "sampleStdev",
    "sampleVariance",
    "save",
    "saveAsHadoopDataset",
    "saveAsHadoopFile",
    "saveAsNewAPIHadoopDataset",
    "saveAsNewAPIHadoopFile",
    "saveAsPickleFile",
    "saveAsSequenceFile",
    "saveAsTable",
    "saveAsTextFile",
    "scalaUDT",
    "schema",
    "schema_of_csv",
    "schema_of_json",
    "sec",
    "second",
    "select",
    "selectExpr",
    "semanticHash",
    "sentences",
    "sequence",
    "sequenceFile",
    "serialize",
    "serve_forever",
    "server_activate",
    "server_bind",
    "server_close",
    "service_actions",
    "session_window",
    "set",
    "setAll",
    "setAppName",
    "setCheckpointDir",
    "setConf",
    "setCurrentCatalog",
    "setCurrentDatabase",
    "setDaemon",
    "setExecutorEnv",
    "setIfMissing",
    "setInterruptOnCancel",
    "setJobDescription",
    "setJobGroup",
    "setLocalProperty",
    "setLogLevel",
    "setMaster",
    "setName",
    "setSparkHome",
    "setSystemProperty",
    "setTimeoutDuration",
    "setTimeoutTimestamp",
    "sha",
    "sha1",
    "sha2",
    "shiftLeft",
    "shiftRight",
    "shiftRightUnsigned",
    "shiftleft",
    "shiftright",
    "shiftrightunsigned",
    "show",
    "show_profiles",
    "shuffle",
    "shutdown",
    "shutdown_request",
    "sign",
    "signature",
    "signum",
    "simpleString",
    "sin",
    "since",
    "sinh",
    "size",
    "skewness",
    "slice",
    "socketserver.close_request",
    "socketserver.fileno",
    "socketserver.finish_request",
    "socketserver.get_request",
    "socketserver.handle_error",
    "socketserver.handle_request",
    "socketserver.handle_timeout",
    "socketserver.process_request",
    "socketserver.serve_forever",
    "socketserver.server_activate",
    "socketserver.server_bind",
    "socketserver.server_close",
    "socketserver.service_actions",
    "socketserver.shutdown_request",
    "socketserver.verify_request",
    "some",
    "sort",
    "sortBy",
    "sortByKey",
    "sortWithinPartitions",
    "sort_array",
    "sorted",
    "soundex",
    "sparkUser",
    "spark_partition_id",
    "split",
    "split_part",
    "sql",
    "sqlType",
    "sqrt",
    "stack",
    "stageId",
    "start",
    "startswith",
    "stats",
    "statusTracker",
    "std",
    "stddev",
    "stddev_pop",
    "stddev_samp",
    "stdev",
    "stop",
    "str_to_map",
    "string.check_unused_args",
    "string.convert_field",
    "string.format",
    "string.format_field",
    "string.get_value",
    "string.parse",
    "string.vformat",
    "struct",
    "subimport",
    "substr",
    "substring",
    "substring_index",
    "subtract",
    "subtractByKey",
    "sum",
    "sumApprox",
    "sumDistinct",
    "sum_distinct",
    "summary",
    "table",
    "tableExists",
    "tableNames",
    "tableProperty",
    "tables",
    "tail",
    "take",
    "takeOrdered",
    "takeSample",
    "tan",
    "tanh",
    "taskAttemptId",
    "tempfile.NamedTemporaryFile",
    "text",
    "textFile",
    "threading.RLock",
    "threading.getName",
    "threading.isDaemon",
    "threading.is_alive",
    "threading.join",
    "threading.run",
    "threading.setDaemon",
    "threading.setName",
    "timestamp_micros",
    "timestamp_millis",
    "timestamp_seconds",
    "to",
    "toDF",
    "toDebugString",
    "toDegrees",
    "toInternal",
    "toJArray",
    "toJSON",
    "toLocalIterator",
    "toPandas",
    "toRadians",
    "toTable",
    "to_arrow_schema",
    "to_arrow_type",
    "to_binary",
    "to_char",
    "to_csv",
    "to_date",
    "to_json",
    "to_koalas",
    "to_number",
    "to_pandas_on_spark",
    "to_str",
    "to_timestamp",
    "to_timestamp_ltz",
    "to_timestamp_ntz",
    "to_unix_timestamp",
    "to_utc_timestamp",
    "to_varchar",
    "top",
    "trace",
    "trace_max_mem",
    "trace_memory_usage",
    "transform",
    "transform_keys",
    "transform_values",
    "translate",
    "treeAggregate",
    "treeReduce",
    "trigger",
    "trim",
    "trunc",
    "try_add",
    "try_aes_decrypt",
    "try_avg",
    "try_divide",
    "try_element_at",
    "try_multiply",
    "try_remote_avro_functions",
    "try_remote_functions",
    "try_remote_observation",
    "try_remote_protobuf_functions",
    "try_remote_session_classmethod",
    "try_remote_window",
    "try_remote_windowspec",
    "try_simplify_traceback",
    "try_subtract",
    "try_sum",
    "try_to_binary",
    "try_to_number",
    "try_to_timestamp",
    "typeName",
    "typeof",
    "typing.NamedTuple",
    "typing.cast",
    "typing.get_type_hints",
    "typing.no_type_check",
    "typing.overload",
    "ucase",
    "udf",
    "udtf",
    "unbase64",
    "uncacheTable",
    "unhex",
    "union",
    "unionAll",
    "unionByName",
    "unix_date",
    "unix_micros",
    "unix_millis",
    "unix_seconds",
    "unix_timestamp",
    "unpersist",
    "unpivot",
    "unregister_pickle_by_value",
    "unset",
    "unwrap_spark_exception",
    "unwrap_udt",
    "update",
    "upper",
    "url_decode",
    "url_encode",
    "user",
    "using",
    "values",
    "var_pop",
    "var_samp",
    "variance",
    "verify_request",
    "version",
    "vformat",
    "walk_tb",
    "warn",
    "warnings.filterwarnings",
    "weekday",
    "weekofyear",
    "when",
    "where",
    "wholeTextFiles",
    "width_bucket",
    "window",
    "window_time",
    "withColumn",
    "withColumnRenamed",
    "withColumns",
    "withColumnsRenamed",
    "withField",
    "withMetadata",
    "withResources",
    "withWatermark",
    "wrap_function",
    "wraps",
    "write",
    "writeTo",
    "write_int",
    "write_long",
    "write_with_length",
    "xpath",
    "xpath_boolean",
    "xpath_double",
    "xpath_float",
    "xpath_int",
    "xpath_long",
    "xpath_number",
    "xpath_short",
    "xpath_string",
    "xxhash64",
    "year",
    "years",
    "zero",
    "zip",
    "zipWithIndex",
    "zipWithUniqueId",
    "zip_with"
  ]
}